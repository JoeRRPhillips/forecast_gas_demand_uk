{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ec3f8df-71dc-4846-bd7a-a8b9d6373b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from typing import Dict\n",
    "\n",
    "from networks.recurrent import AutoRegressiveMultiStepLSTM\n",
    "\n",
    "config: Dict = {\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": 2,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"test_data_filepath\": \"/mnt/c/Users/JPhillips/ldz/data/processed/test.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497832d6-e4cc-4167-8929-92ade6e5e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 17:44:10.063861: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: UNKNOWN ERROR (304)\n",
      "2022-05-17 17:44:10.064040: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (NADT99): /proc/driver/nvidia/version does not exist\n",
      "2022-05-17 17:44:10.064894: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "test_df = pd.read_csv(config[\"test_data_filepath\"])\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(np.array(test_df))\n",
    "# test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3955c46-c9c5-4740-b871-feb52cbe426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.load_model(cfg.predict.saved_model_path)\n",
    "model = AutoRegressiveMultiStepLSTM(\n",
    "    recurrent_units=256,\n",
    "    num_features=66,   # Must match train_df.shape[1].\n",
    "    num_out_steps=24,  # Must match config_data[\"window_label_width\"].\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb9144c6-06e2-44ab-8587-1f4c23ba0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = tf.losses.MeanSquaredError(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebf9b731-beac-4e73-8c02-fe7d311a6243",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a194b89-aa6c-4e8c-bb12-32db95b60657",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68ae7597-6850-4e08-8e06-92a49e958627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 72), dtype=float64, numpy=\n",
       "array([[0.45936016, 0.36572433, 0.4548724 , 0.191038  , 0.47776333,\n",
       "        0.45662473, 0.36224692, 0.46258746, 0.17518121, 0.76280574,\n",
       "        0.44165699, 0.35646428, 0.3553595 , 0.13807089, 0.54663346,\n",
       "        0.42051986, 0.34746386, 0.33176538, 0.13878284, 0.67548312,\n",
       "        0.45936016, 0.36572433, 0.4548724 , 0.191038  , 0.47776333,\n",
       "        0.4316278 , 0.35538444, 0.42616191, 0.15806331, 0.55658164,\n",
       "        0.41527822, 0.34802442, 0.24700352, 0.08367039, 0.40055097,\n",
       "        0.47622141, 0.36894862, 0.44583313, 0.1749343 , 0.17549296,\n",
       "        0.47986177, 0.36943639, 0.41303588, 0.14510009, 0.23230139,\n",
       "        0.49013648, 0.37132338, 0.43446622, 0.10837624, 0.53093145,\n",
       "        0.44336365, 0.35684015, 0.46515668, 0.15707774, 0.78706977,\n",
       "        0.45491264, 0.35939742, 0.38947688, 0.11980155, 0.75570968,\n",
       "        0.45112997, 0.35600149, 0.40938574, 0.11746852, 0.73561293,\n",
       "        0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 1.        ]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c9e5549-1830-4378-aae7-d6692d045dfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"rnn\" (type RNN).\n\nShape (72, 1) must have rank at least 3\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(1, 72), dtype=float32)\n  • mask=None\n  • training=None\n  • initial_state=None\n  • constants=None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtest_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/mnt/c/Users/JPhillips/ldz/networks/recurrent.py:23\u001B[0m, in \u001B[0;36mAutoRegressiveMultiStepRNN.call\u001B[0;34m(self, inputs, training)\u001B[0m\n\u001B[1;32m     20\u001B[0m predictions \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Initialize the LSTM state.\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m prediction, state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwarmup\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m predictions\u001B[38;5;241m.\u001B[39mappend(prediction)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_out_steps):\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m# Use the last prediction as input.\u001B[39;00m\n",
      "File \u001B[0;32m/mnt/c/Users/JPhillips/ldz/networks/recurrent.py:50\u001B[0m, in \u001B[0;36mAutoRegressiveMultiStepRNN.warmup\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwarmup\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;66;03m# inputs.shape -> [batch, time, features]\u001B[39;00m\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;66;03m# x.shape -> [batch, recurrent_units]\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m     x, \u001B[38;5;241m*\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;66;03m# prediction.shape -> [batch, num_features]\u001B[39;00m\n\u001B[1;32m     53\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdense(x)\n",
      "\u001B[0;31mValueError\u001B[0m: Exception encountered when calling layer \"rnn\" (type RNN).\n\nShape (72, 1) must have rank at least 3\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(1, 72), dtype=float32)\n  • mask=None\n  • training=None\n  • initial_state=None\n  • constants=None"
     ]
    }
   ],
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "397186a6-43ff-4dbe-a57b-080adc788ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 17:45:25.909480: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open /mnt/c/Users/JPhillips/ldz/outputs/2022-05-17/16-00-33/saved_models/checkpoints/AutoRegressiveMultiStepLSTM/saved_model.pb: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# model.built = True\u001B[39;00m\n\u001B[1;32m      3\u001B[0m saved_model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/mnt/c/Users/JPhillips/ldz/outputs/2022-05-17/16-00-33/saved_models/checkpoints/AutoRegressiveMultiStepLSTM/saved_model.pb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 4\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_weights\u001B[49m\u001B[43m(\u001B[49m\u001B[43msaved_model_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/keras/engine/training.py:2593\u001B[0m, in \u001B[0;36mModel.load_weights\u001B[0;34m(self, filepath, by_name, skip_mismatch, options)\u001B[0m\n\u001B[1;32m   2589\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m   2590\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`load_weights` requires h5py package when loading weights from \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   2591\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHDF5. Try installing h5py.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   2592\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_graph_network \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuilt:\n\u001B[0;32m-> 2593\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2594\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnable to load weights saved in HDF5 format into a subclassed \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   2595\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel which has not created its variables yet. Call the Model \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   2596\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst, then load the weights.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   2597\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assert_weights_created()\n\u001B[1;32m   2598\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m h5py\u001B[38;5;241m.\u001B[39mFile(filepath, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "\u001B[0;31mValueError\u001B[0m: Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights."
     ]
    }
   ],
   "source": [
    "# model.built = True\n",
    "\n",
    "saved_model_path = \"/mnt/c/Users/JPhillips/ldz/outputs/2022-05-17/16-00-33/saved_models/checkpoints/AutoRegressiveMultiStepLSTM/saved_model.pb\"\n",
    "model.load_weights(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e275fd3-01a8-4b8c-881f-450ee1f510c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}